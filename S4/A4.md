##  Part 2

### Model
The CNN Pipeline consists of 3 CNN layers each of 16, 32 and 50 channels respectively. 
Each channel has a BatchNormalization,Dropout and MaxPooling step to it. 

Kernel size selected is 3x3 and padding is set to 1 to preserve the resolution of the channels at each CNN layer. 
After each layer, batch norm followed by a dropout of 5% is applied.
The resolution is reduced using MaxPooling after each CNN layer.
The activation function used is ReLU.
The Fully Connected layer 
The output of the CNN Pipeline is fed to a fully connected layer of 10 nuerons followed by a Dropout step.

Training has been done on GPU
Learning rate lr=0.01 
Momentum = 0.9
Batch size of 32, 64, 128, 256 were experimented. 

As per the problem statement, the total number of parameters of the network is 19,848 (< 20k) and the number of epochs trained is 19 (< 20 epochs)
The final accuracy (at the end of 19th epoch ) is 99.28 % 

