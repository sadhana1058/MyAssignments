##  Part 2

### Model
* The CNN Pipeline consists of 3 CNN layers each of 16, 32 and 50 channels respectively. 
* Each channel has a BatchNormalization,Dropout and MaxPooling step to it. 

* Kernel size selected is 3x3 and padding is set to 1 to preserve the resolution of the channels at each CNN layer. 
* After each layer, batch norm followed by a dropout of 5% is applied.
* The resolution is reduced using MaxPooling after each CNN layer.
* The activation function used is ReLU.
* Our last layer is the Fully Connected layer 
* The output of the CNN Pipeline is fed to a fully connected layer of 10 nuerons followed by a Dropout step.

* Training has been done on GPU
* Learning rate lr=0.01 
* Momentum = 0.9
* Batch size of 32, 64, 128, 256 were experimented. 

* As per the problem statement, the total number of parameters of the network is 19,848 (< 20k) and the number of epochs trained is 19 (< 20 epochs)
* The final accuracy (at the end of 19th epoch ) is 99.28 % 

### Model Summary

```
----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1           [-1, 16, 28, 28]             144
              ReLU-2           [-1, 16, 28, 28]               0
       BatchNorm2d-3           [-1, 16, 28, 28]              32
           Dropout-4           [-1, 16, 28, 28]               0
         MaxPool2d-5           [-1, 16, 14, 14]               0
            Conv2d-6           [-1, 32, 14, 14]           4,608
              ReLU-7           [-1, 32, 14, 14]               0
       BatchNorm2d-8           [-1, 32, 14, 14]              64
           Dropout-9           [-1, 32, 14, 14]               0
        MaxPool2d-10             [-1, 32, 3, 3]               0
           Conv2d-11             [-1, 50, 3, 3]          14,400
             ReLU-12             [-1, 50, 3, 3]               0
      BatchNorm2d-13             [-1, 50, 3, 3]             100
          Dropout-14             [-1, 50, 3, 3]               0
        MaxPool2d-15             [-1, 50, 1, 1]               0
           Linear-16                   [-1, 10]             500
================================================================
Total params: 19,848
Trainable params: 19,848
Non-trainable params: 0
----------------------------------------------------------------
```

### Training Logs
```
Epoch Number =  1
loss=0.062293101102113724 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 22.11it/s]

Test set: Average loss: 0.0492, Accuracy: 9847/10000 (98%)

Epoch Number =  2
loss=0.040206607431173325 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.78it/s]

Test set: Average loss: 0.0356, Accuracy: 9886/10000 (99%)

Epoch Number =  3
loss=0.08588200807571411 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.85it/s]

Test set: Average loss: 0.0344, Accuracy: 9895/10000 (99%)

Epoch Number =  4
loss=0.0371597521007061 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.82it/s]

Test set: Average loss: 0.0321, Accuracy: 9907/10000 (99%)

Epoch Number =  5
loss=0.003993797581642866 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.96it/s]

Test set: Average loss: 0.0300, Accuracy: 9906/10000 (99%)

Epoch Number =  6
loss=0.08285342901945114 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.72it/s]

Test set: Average loss: 0.0332, Accuracy: 9896/10000 (99%)

Epoch Number =  7
loss=0.0075829848647117615 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.88it/s]

Test set: Average loss: 0.0265, Accuracy: 9914/10000 (99%)

Epoch Number =  8
loss=0.01992647349834442 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.62it/s]

Test set: Average loss: 0.0297, Accuracy: 9913/10000 (99%)

Epoch Number =  9
loss=0.004099078942090273 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.75it/s]

Test set: Average loss: 0.0290, Accuracy: 9915/10000 (99%)

Epoch Number =  10
loss=0.019100770354270935 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.72it/s]

Test set: Average loss: 0.0265, Accuracy: 9912/10000 (99%)

Epoch Number =  11
loss=0.029913706704974174 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.76it/s]

Test set: Average loss: 0.0260, Accuracy: 9916/10000 (99%)

Epoch Number =  12
loss=0.0032055082265287638 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.69it/s]

Test set: Average loss: 0.0251, Accuracy: 9928/10000 (99%)

Epoch Number =  13
loss=0.018713297322392464 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.67it/s]

Test set: Average loss: 0.0271, Accuracy: 9913/10000 (99%)

Epoch Number =  14
loss=0.019832104444503784 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.62it/s]

Test set: Average loss: 0.0276, Accuracy: 9920/10000 (99%)

Epoch Number =  15
loss=0.019311852753162384 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.87it/s]

Test set: Average loss: 0.0259, Accuracy: 9914/10000 (99%)

Epoch Number =  16
loss=0.008246871642768383 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.85it/s]

Test set: Average loss: 0.0285, Accuracy: 9903/10000 (99%)

Epoch Number =  17
loss=0.020872652530670166 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 22.22it/s]

Test set: Average loss: 0.0278, Accuracy: 9920/10000 (99%)

Epoch Number =  18
loss=0.001436802209354937 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.98it/s]

Test set: Average loss: 0.0256, Accuracy: 9924/10000 (99%)

Epoch Number =  19
loss=0.004901103209704161 batch_id=468: 100%|██████████| 469/469 [00:21<00:00, 21.54it/s]

Test set: Average loss: 0.0275, Accuracy: 9928/10000 (99%)

```

