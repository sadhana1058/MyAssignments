{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"2_5_Pytorch101_Assigned_Work.ipynb","provenance":[],"authorship_tag":"ABX9TyOClLorx+RARfZBmTMk5fdB"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"XkGiuFfXN-Nx"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Y3gqkljD5k9S"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RoVIfwz7-KBF"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JyJ-nfm_5k83","executionInfo":{"status":"ok","timestamp":1634356281295,"user_tz":-330,"elapsed":24905,"user":{"displayName":"Sadhana S","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03854109618425223886"}}},"source":["#importing the necessary modules\n","\n","from __future__ import print_function\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","\n","import torchvision\n","import torchvision.transforms as transforms"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"k0locgs65k9A","executionInfo":{"status":"ok","timestamp":1634356281937,"user_tz":-330,"elapsed":657,"user":{"displayName":"Sadhana S","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03854109618425223886"}}},"source":["#creating our hybrid model which can accept both image and tabular data\n","\n","class Network(nn.Module):\n","    def __init__(self):\n","        super(Network, self).__init__()\n","        #for Image data \n","\n","  #first let us identify the mnist number from mnist image\n","\n","        # input 28 # output 24 # receptive_field = 5\n","        self.conv1 = nn.Conv2d(in_channels=1, out_channels=20, kernel_size=5)\n","        #relu=> maxpool =>24*24*20=> output =>12*12*20 RF=10*10\n","\n","        # input 12 # output 8 # receptive_field = 14*14\n","        self.conv2 = nn.Conv2d(in_channels=20, out_channels=40, kernel_size=5)\n","        #relu=> maxpool =>8*8*40=> output =>4*4*40 RF=28*28\n","\n","\n","        #input 4*4*50 output = 100\n","        self.fc1 = nn.Linear(4*4*40, 100)#we have taken batch size of 100\n","\n","\n","\n","        ## for tabular data, to sum our random number\n","        \n","        self.tabular_fc_rn= nn.Linear(110, 200) \n","        self.fc3 = nn.Linear(200, 50) \n","        #converting it to one hot encoded output\n","        self.fc4 = nn.Linear(50,29)\n","\n","    def forward(self, img,tab):\n","        img = F.relu(self.conv1(img))\n","        img = F.max_pool2d(img, 2, 2)\n","        img = F.relu(self.conv2(img))\n","        img = F.max_pool2d(img, 2, 2)\n","        #we are reshaping our tensor in order to flatten our layer into fully connected layer\n","        # We are reshaping it to have 4*4*40 number of columns and \n","        #telling Pytorch to decide the number of rows by itself by giving -1 as parameter \n","        img = img.view(-1, 4*4*40)\n","        img = self.fc1(img)\n","\n","        # combining mnist image with tabular data random number\n","        x = torch.cat((img, tab), dim=1)\n","\n","        #oassing it to the network to recognize and sum the data\n","        x = self.fc4(F.relu(self.fc3(F.relu(self.tabular_fc_rn(x)))))\n","        img = x[:,0:10]\n","        tab = x[:,10:]\n","        \n","\n","        #returning  mnist number and sum of random numbr\n","        return  F.log_softmax(img, dim=1),F.log_softmax(tab, dim=1)\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"sGgNUwIz5k9D","executionInfo":{"status":"ok","timestamp":1634356281940,"user_tz":-330,"elapsed":36,"user":{"displayName":"Sadhana S","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03854109618425223886"}}},"source":["\n","from torchsummary import summary\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mmijK09u5k9G","executionInfo":{"status":"ok","timestamp":1634356281942,"user_tz":-330,"elapsed":36,"user":{"displayName":"Sadhana S","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03854109618425223886"}},"outputId":"e59f6b31-8416-42d2-8b31-93cc298f3293"},"source":["device"],"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"PYJMrsbg5k9I","executionInfo":{"status":"ok","timestamp":1634356469503,"user_tz":-330,"elapsed":818,"user":{"displayName":"Sadhana S","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03854109618425223886"}}},"source":["from torch.utils.data import Dataset\n","import torch.nn.functional as F\n","\n","#creating  a custom dataset for training a network with 2 inputs\n","\n","class MyDataset_train(Dataset):\n","    def __init__(self, tabular_data):\n","        #Initializing data\n","        self.RandomNumberdata = tabular_data\n","        self.MNISTImagedata = torchvision.datasets.MNIST('../data', train=True, download=True,\n","                    transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                    ]))\n","        \n","    def __getitem__(self, index):\n","        r = self.RandomNumberdata[index]\n","        RandomNumber = F.one_hot(r, num_classes = 10).type(torch.float32).requires_grad_(True)\n","        \n","        MNISTimage, MNISTlabel = self.MNISTImagedata[index] \n","        \n","        # for random number label is the number itelf\n","        # we are creating a label for our network to get trained to compute sum\n","        Sum_label = r.item() + MNISTlabel \n","\n","        #returning multiple items\n","        return RandomNumber, Sum_label, MNISTimage, MNISTlabel\n","    \n","    def __len__(self):\n","        return len(self.RandomNumberdata)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"VKYrZoA_5k9J","executionInfo":{"status":"ok","timestamp":1634356470962,"user_tz":-330,"elapsed":8,"user":{"displayName":"Sadhana S","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03854109618425223886"}}},"source":["# creating a tensor of random numbers with a size equal to that of train data\n","random_number_tensor = torch.randint(low=0,high=9,size=(60000,))\n","\n","myRNMNIST_train = MyDataset_train(random_number_tensor)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"adkxcOD35k9K","executionInfo":{"status":"ok","timestamp":1634356473292,"user_tz":-330,"elapsed":7,"user":{"displayName":"Sadhana S","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03854109618425223886"}}},"source":["batch_size = 100\n","#declared a batch size of 100\n","train_RNMNIST_loader = torch.utils.data.DataLoader(myRNMNIST_train, batch_size = batch_size, shuffle=True)"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"9UnrENWx5k9M","executionInfo":{"status":"ok","timestamp":1634356486091,"user_tz":-330,"elapsed":525,"user":{"displayName":"Sadhana S","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03854109618425223886"}}},"source":["# creating a dataset for training\n","class MyDataset_test(Dataset):\n","    def __init__(self, data_array):\n","        self.RandomNumberdata = data_array\n","        self.MNISTdata = torchvision.datasets.MNIST('../data', train=False, download=True,\n","                    transform=transforms.Compose([\n","                        transforms.ToTensor(),\n","                        transforms.Normalize((0.1307,), (0.3081,))\n","                    ]))\n","        \n","    def __getitem__(self, index):\n","        r = self.RandomNumberdata[index]\n","        #performing one hot encoding to faster theadding of two numbers training\n","        RandomNumber = F.one_hot(r, num_classes = 10).type(torch.float32)\n","\n","        MNISTimage, MNISTlabel = self.MNISTdata[index] \n","        \n","       #creating sum label\n","        SUMlabel = r.item() + MNISTlabel \n","        \n","        return RandomNumber, SUMlabel, MNISTimage, MNISTlabel\n","    \n","    def __len__(self):\n","        return len(self.RandomNumberdata)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"IETCsPtQ5k9O","executionInfo":{"status":"ok","timestamp":1634356488131,"user_tz":-330,"elapsed":4,"user":{"displayName":"Sadhana S","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03854109618425223886"}}},"source":["#generating random number tensor\n","random_tensor_test = torch.randint(low=0,high=9,size=(10000,))\n","\n","myRNMNIST_test = MyDataset_test(random_tensor_test)\n","\n","test_RNMNIST_loader = torch.utils.data.DataLoader(myRNMNIST_test, batch_size = batch_size, shuffle=True)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"rYSZ0hbs5k9Q","executionInfo":{"status":"ok","timestamp":1634356535338,"user_tz":-330,"elapsed":662,"user":{"displayName":"Sadhana S","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03854109618425223886"}}},"source":["from tqdm import tqdm\n","#creating functions for traing and testing our model\n","def train(model, device, train_loader, optimizer, epoch):\n","    model.train()\n","    pbar = tqdm(train_loader)\n","    for batch_idx, (rn_number, rn_sum_label, mnist_image, mnist_label) in enumerate(pbar):\n","\n","        # TRAINING ON GPU\n","        rn_number, rn_sum_label = rn_number.to(device), rn_sum_label.to(device)\n","        mnist_image, mnist_label = mnist_image.to(device), mnist_label.to(device)\n","        \n","        optimizer.zero_grad()\n","\n","        output_image, output_rnd_sum = model(mnist_image, rn_number)\n","        \n","        loss_mnist_img = F.nll_loss(output_image, mnist_label) # LOSS FOR PREDICTING MNIST LABEL\n","        loss_sum_rn_mn = F.nll_loss(output_rnd_sum, rn_sum_label)# LOSS FOR PREDICTING SUM LABEL\n","        \n","        #adding both losses as overall loss\n","        loss = loss_mnist_img + loss_sum_rn_mn\n","        loss.backward()\n","        optimizer.step()\n","        #using progress bar to show output\n","        pbar.set_description(desc= f'MNIST loss={loss_mnist_img.item()} SUM loss={loss_sum_rn_mn.item()} batch_id={batch_idx}')\n","\n","def test(model, device, test_loader):\n","    model.eval()\n","    test_loss_mnist = 0\n","    test_loss_sum = 0\n","    correct_mnist = 0\n","    correct_sum = 0\n","    with torch.no_grad():\n","        for rn_number, rn_sum_label, mnist_image, mnist_label in test_loader:\n","            \n","            rn_number, rn_sum_label = rn_number.to(device), rn_sum_label.to(device)\n","            mnist_image, mnist_label = mnist_image.to(device), mnist_label.to(device)\n","            \n","            output_image, output_rnd_sum = model(mnist_image, rn_number)\n","            \n","            test_loss_mnist += F.nll_loss(output_image, mnist_label, reduction='sum').item()\n","            test_loss_sum += F.nll_loss(output_rnd_sum, rn_sum_label, reduction='sum').item()\n","\n","            pred_mnist = output_image.argmax(dim=1, keepdim=True)  \n","            pred_sum = output_rnd_sum.argmax(dim=1, keepdim=True)\n","            \n","            correct_mnist += pred_mnist.eq(mnist_label.view_as(pred_mnist)).sum().item()\n","            correct_sum += pred_sum.eq(rn_sum_label.view_as(pred_sum)).sum().item()\n","\n","    test_loss_mnist /= len(test_loader.dataset)\n","    test_loss_sum /= len(test_loader.dataset)\n","  #printing losses and efficiency\n","  \n","    print('\\nTest set: Average MNIST loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","        test_loss_mnist, correct_mnist, len(test_loader.dataset),\n","        100. * correct_mnist / len(test_loader.dataset)))\n","    \n","    print('\\nTest set: Average SUM loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","        test_loss_sum, correct_sum, len(test_loader.dataset),\n","        100. * correct_sum / len(test_loader.dataset)))"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"scrolled":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"ldyOFWtM5k9R","executionInfo":{"status":"ok","timestamp":1634356837968,"user_tz":-330,"elapsed":300736,"user":{"displayName":"Sadhana S","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03854109618425223886"}},"outputId":"49f57993-03b8-45c8-c1ba-0d7453890602"},"source":["network = Network().to(device)\n","optimizer = optim.SGD(network.parameters(), lr=0.01, momentum=0.9)\n","\n","torch.set_printoptions(edgeitems=11)\n","\n","\n","for epoch in range(1, 11):\n","    train(network, device, train_RNMNIST_loader, optimizer, epoch)\n","    test(network, device, test_RNMNIST_loader)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/600 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n","  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n","MNIST loss=0.11605943739414215 SUM loss=2.2462875843048096 batch_id=599: 100%|██████████| 600/600 [00:26<00:00, 23.05it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average MNIST loss: 0.0722, Accuracy: 9789/10000 (98%)\n","\n","\n","Test set: Average SUM loss: 2.2212, Accuracy: 1526/10000 (15%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["MNIST loss=0.07319030910730362 SUM loss=1.151845932006836 batch_id=599: 100%|██████████| 600/600 [00:25<00:00, 23.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average MNIST loss: 0.0494, Accuracy: 9848/10000 (98%)\n","\n","\n","Test set: Average SUM loss: 1.1579, Accuracy: 5198/10000 (52%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["MNIST loss=0.02641809731721878 SUM loss=0.6257476806640625 batch_id=599: 100%|██████████| 600/600 [00:25<00:00, 23.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average MNIST loss: 0.0427, Accuracy: 9874/10000 (99%)\n","\n","\n","Test set: Average SUM loss: 0.6275, Accuracy: 8330/10000 (83%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["MNIST loss=0.01806974969804287 SUM loss=0.10651952028274536 batch_id=599: 100%|██████████| 600/600 [00:25<00:00, 23.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average MNIST loss: 0.0411, Accuracy: 9870/10000 (99%)\n","\n","\n","Test set: Average SUM loss: 0.1621, Accuracy: 9742/10000 (97%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["MNIST loss=0.0030549338553100824 SUM loss=0.052115391939878464 batch_id=599: 100%|██████████| 600/600 [00:25<00:00, 23.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average MNIST loss: 0.0331, Accuracy: 9892/10000 (99%)\n","\n","\n","Test set: Average SUM loss: 0.0859, Accuracy: 9825/10000 (98%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["MNIST loss=0.052450038492679596 SUM loss=0.1129785031080246 batch_id=599: 100%|██████████| 600/600 [00:25<00:00, 23.55it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average MNIST loss: 0.0257, Accuracy: 9915/10000 (99%)\n","\n","\n","Test set: Average SUM loss: 0.0683, Accuracy: 9857/10000 (99%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["MNIST loss=0.01933237724006176 SUM loss=0.07879118621349335 batch_id=599: 100%|██████████| 600/600 [00:25<00:00, 23.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average MNIST loss: 0.0336, Accuracy: 9896/10000 (99%)\n","\n","\n","Test set: Average SUM loss: 0.0746, Accuracy: 9839/10000 (98%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["MNIST loss=0.0014284619828686118 SUM loss=0.014636061154305935 batch_id=599: 100%|██████████| 600/600 [00:25<00:00, 23.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average MNIST loss: 0.0289, Accuracy: 9903/10000 (99%)\n","\n","\n","Test set: Average SUM loss: 0.0609, Accuracy: 9870/10000 (99%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["MNIST loss=0.002785096876323223 SUM loss=0.019118690863251686 batch_id=599: 100%|██████████| 600/600 [00:25<00:00, 23.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average MNIST loss: 0.0315, Accuracy: 9911/10000 (99%)\n","\n","\n","Test set: Average SUM loss: 0.0589, Accuracy: 9867/10000 (99%)\n","\n"]},{"output_type":"stream","name":"stderr","text":["MNIST loss=0.003368350211530924 SUM loss=0.025412114337086678 batch_id=599: 100%|██████████| 600/600 [00:25<00:00, 23.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","Test set: Average MNIST loss: 0.0288, Accuracy: 9903/10000 (99%)\n","\n","\n","Test set: Average SUM loss: 0.0471, Accuracy: 9890/10000 (99%)\n","\n"]}]},{"cell_type":"code","metadata":{"id":"d6KWiCOFONXs"},"source":[""],"execution_count":null,"outputs":[]}]}